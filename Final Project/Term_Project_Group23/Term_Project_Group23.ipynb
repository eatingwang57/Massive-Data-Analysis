{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf, SparkFiles\n",
    "# sc.stop()\n",
    "# conf = SparkConf().set(\"spark.default.parallelism\", 4).set('spark.driver.maxResultSize', '10G')\n",
    "# sc =  SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART1\n",
    "# mapper1\n",
    "def readFile(line):\n",
    "    result = line.split(',')\n",
    "    if (not result[0].isdigit()):\n",
    "        return\n",
    "    else:\n",
    "        return int(result[1]), [[int(result[0]), result[2]]]\n",
    "        # movieID, [userID, rating]\n",
    "\n",
    "def reducer1(a, b):\n",
    "    return a+b\n",
    "\n",
    "def Calculate(line):\n",
    "    # line = (movieID, [userID, rating])\n",
    "    total = 0\n",
    "    subMean = []\n",
    "    subMeanSqr = 0\n",
    "    merge = []\n",
    "    for person in line[1]:\n",
    "        total += float(person[1])\n",
    "    mean = total / len(line[1])\n",
    "    \n",
    "    for person in line[1]:\n",
    "        subMean.append(float(person[1]) - mean)\n",
    "        subMeanSqr += pow(float(person[1]) - mean, 2)\n",
    "    subMeanSqr = pow(subMeanSqr, 0.5)\n",
    "    \n",
    "    for i in range(len(line[1])):\n",
    "        merge.append((line[1][i][0], [[line[0], subMean[i], subMeanSqr]]))\n",
    "        # userID, [movieID, rating to this movie - mean, meanSquare]\n",
    "    return merge\n",
    "\n",
    "def Similarity(line):\n",
    "    # line = userID, [ [movieID, rating-mean, meanSquare], [movieID, rating-mean, meanSquare], ... ]\n",
    "    tmp = []\n",
    "    for i in range(len(line[1])):\n",
    "        for j in range(i + 1, len(line[1])):\n",
    "            length = line[1][i][2] * line[1][j][2]\n",
    "            if length == 0:\n",
    "                tmp.append(((line[1][i][0], line[1][j][0]),[0]))\n",
    "            else:\n",
    "                tmp.append(((line[1][i][0], line[1][j][0]), [line[1][i][1] * line[1][j][1] / length]))\n",
    "            # (moveID1, moveID2), [sim])\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def Add(line):\n",
    "    tmp = 0\n",
    "    for sim in line[1]:\n",
    "        tmp += sim\n",
    "    return line[0], tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"smallData.csv\"\n",
    "file = sc.textFile(path)\n",
    "\n",
    "m1 = file.map(readFile).filter(lambda x: x != None).reduceByKey(reducer1).sortByKey(True)\n",
    "\n",
    "# for i in m1.collect():\n",
    "#     print(i)\n",
    "\n",
    "m2 = m1.flatMap(Calculate).reduceByKey(reducer1)\n",
    "m3 = m2.flatMap(Similarity).reduceByKey(reducer1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = m3.map(Add).sortByKey(True)\n",
    "m3 = m3.collect()\n",
    "outputfile = open(\"OutputFile.txt\", \"w\")\n",
    "for i in range(len(m3)):\n",
    "    outputfile.write(\"(\" + str(m3[i][0][0]) + ', ' + str(m3[i][0][1]) + ') : ' + str(m3[i][1]))\n",
    "    outputfile.write('\\n')\n",
    "outputfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
